import pandas as pd
from keybert import KeyBERT
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from underthesea import word_tokenize
import numpy as np
import torch
import re

# Load data
print("ğŸ“‚ Loading restaurant data...")
df = pd.read_csv(r"C:\python\Projects\TOURISM\AI\Data-master\restaurants_100_improved.csv")

# Convert columns to string and handle NaN
df["tags"] = df["tags"].fillna("").astype(str)
df["city"] = df["city"].fillna("").astype(str)
df["name"] = df["name"].fillna("").astype(str)
df["cuisine"] = df["cuisine"].fillna("").astype(str)
df["rating"] = pd.to_numeric(df["rating"], errors='coerce').fillna(0)

# Initialize models
print("ğŸ¤– Loading AI models...")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"   Using device: {device}")

model = SentenceTransformer("keepitreal/vietnamese-sbert", device=device)
kw_model = KeyBERT(model=model)
embed_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)

# Vietnamese stop words (expanded)
stop_words_vi = [
    'cá»§a', 'vÃ ', 'cÃ¡c', 'cÃ³', 'Ä‘Æ°á»£c', 'cho', 'lÃ ', 'vá»›i', 
    'Ä‘á»ƒ', 'trong', 'khÃ´ng', 'má»™t', 'nÃ y', 'nhá»¯ng', 'Ä‘Ã£', 
    'nhÆ°', 'bá»Ÿi', 'tá»«', 'hoáº·c', 'Ä‘áº¿n', 'khi', 'cÅ©ng', 'nhÆ°ng',
    'thÃ¬', 'nÃ o', 'Ä‘Ã¢y', 'ráº¥t', 'sáº½', 'vÃ o', 'ra', 'á»Ÿ', 'vá»'
]

# Cuisine keywords for better matching
cuisine_keywords = {
    'Viá»‡t Nam': ['viá»‡t nam', 'phá»Ÿ', 'bÃºn', 'cÆ¡m táº¥m', 'bÃ¡nh mÃ¬', 'gá»i cuá»‘n', 'nem', 'cháº£'],
    'Nháº­t Báº£n': ['nháº­t', 'nháº­t báº£n', 'sushi', 'ramen', 'sashimi', 'tempura', 'udon'],
    'HÃ n Quá»‘c': ['hÃ n', 'hÃ n quá»‘c', 'korea', 'bulgogi', 'kimchi', 'bbq hÃ n', 'bibimbap'],
    'ThÃ¡i': ['thÃ¡i', 'thÃ¡i lan', 'thai', 'pad thai', 'tom yum', 'cÃ  ri thÃ¡i'],
    'Trung Quá»‘c': ['trung quá»‘c', 'dimsum', 'dimsum', 'vá»‹t quay', 'mÃ¬ trung hoa'],
    'Ã‚u': ['Ã¢u', 'Ã½', 'phÃ¡p', 'pasta', 'pizza', 'steak', 'má»³ Ã½'],
    'áº¤n Äá»™': ['áº¥n Ä‘á»™', 'áº¥n', 'cÃ  ri áº¥n', 'tandoori', 'biryani', 'naan'],
    'Má»¹': ['má»¹', 'burger', 'hamburger', 'bbq má»¹', 'steak má»¹'],
    'Äá»‹a Trung Háº£i': ['Ä‘á»‹a trung háº£i', 'kebab', 'hummus', 'falafel', 'hy láº¡p']
}

def preprocess_vi(text):
    """Preprocess Vietnamese text"""
    text = str(text).lower()
    text = word_tokenize(text, format="text")
    return text

def extract_city(user_input):
    """Extract city from user input with flexible matching"""
    user_lower = user_input.lower()
    
    city_keywords = {
        "ÄÃ  Náºµng": ["Ä‘Ã  náºµng", "da nang", "Ä‘n", "danang"],
        "Há»“ ChÃ­ Minh": ["há»“ chÃ­ minh", "hcm", "sÃ i gÃ²n", "saigon", "tphcm", "tp hcm"],
        "HÃ  Ná»™i": ["hÃ  ná»™i", "ha noi", "hn", "hanoi"],
        "Nha Trang": ["nha trang"],
        "ÄÃ  Láº¡t": ["Ä‘Ã  láº¡t", "da lat", "dalat"],
        "Cáº§n ThÆ¡": ["cáº§n thÆ¡", "can tho"],
        "Huáº¿": ["huáº¿", "hue"],
        "Háº£i PhÃ²ng": ["háº£i phÃ²ng", "hai phong"],
        "VÅ©ng TÃ u": ["vÅ©ng tÃ u", "vung tau"],
        "PhÃº Quá»‘c": ["phÃº quá»‘c", "phu quoc"]
    }
    
    for city, keywords in city_keywords.items():
        if any(kw in user_lower for kw in keywords):
            return city
    return None

def extract_cuisine(user_input):
    """Extract cuisine preference from user input"""
    user_lower = user_input.lower()
    
    for cuisine, keywords in cuisine_keywords.items():
        if any(kw in user_lower for kw in keywords):
            return cuisine
    return None

def extract_price_preference(user_input):
    """Extract price preference from user input"""
    user_lower = user_input.lower()
    
    cheap_keywords = ['ráº»', 'bÃ¬nh dÃ¢n', 'sinh viÃªn', 'tiáº¿t kiá»‡m', 'budget', 'cheap']
    mid_keywords = ['vá»«a pháº£i', 'trung bÃ¬nh', 'há»£p lÃ½']
    expensive_keywords = ['cao cáº¥p', 'sang trá»ng', 'Ä‘áº¯t', 'fine dining', 'luxury']
    
    if any(kw in user_lower for kw in cheap_keywords):
        return 'â‚«'
    elif any(kw in user_lower for kw in expensive_keywords):
        return 'â‚«â‚«â‚«'
    elif any(kw in user_lower for kw in mid_keywords):
        return 'â‚«â‚«'
    return None

def extract_atmosphere_tags(user_input):
    """Extract atmosphere preferences from user input"""
    user_lower = user_input.lower()
    atmosphere_tags = []
    
    tag_keywords = {
        'romantic': ['lÃ£ng máº¡n', 'háº¹n hÃ²', 'couple', 'romantic'],
        'family': ['gia Ä‘Ã¬nh', 'family', 'Ä‘Ã´ng ngÆ°á»i'],
        'view': ['view', 'cáº£nh Ä‘áº¹p', 'rooftop', 'sÃ¢n thÆ°á»£ng'],
        'quiet': ['yÃªn tÄ©nh', 'quiet', 'tÄ©nh láº·ng'],
        'modern': ['hiá»‡n Ä‘áº¡i', 'modern', 'trendy'],
        'vegetarian': ['chay', 'vegetarian', 'vegan'],
        'halal': ['halal'],
        'delivery': ['delivery', 'giao hÃ ng', 'Ä‘áº·t vá»'],
        'cheap': ['ráº»', 'bÃ¬nh dÃ¢n', 'giÃ¡ tá»‘t']
    }
    
    for tag, keywords in tag_keywords.items():
        if any(kw in user_lower for kw in keywords):
            atmosphere_tags.append(tag)
    
    return atmosphere_tags

# Pre-compute restaurant embeddings for efficiency
print("ğŸ”„ Pre-computing restaurant embeddings...")
# Combine tags, cuisine, and name for richer embeddings
df["search_text"] = df["tags"] + " " + df["cuisine"] + " " + df["name"]
restaurant_embeddings = embed_model.encode(df["search_text"].tolist(), show_progress_bar=True)
df["embedding"] = list(restaurant_embeddings)

def calculate_weighted_score(row, similarity, rating_weight=0.2):
    """Calculate weighted score combining similarity and rating"""
    normalized_rating = row['rating'] / 5.0  # Normalize to 0-1
    final_score = (1 - rating_weight) * similarity + rating_weight * normalized_rating
    return final_score

def recommend_restaurants(user_input, city_filter=None, cuisine_filter=None, 
                         price_filter=None, top_n=5, use_rating=True):
    """Recommend restaurants based on user input with multiple filters"""
    
    if not user_input.strip():
        print("âš ï¸ Please enter what you want to eat!")
        return pd.DataFrame()
    
    tokenized_text = word_tokenize(user_input, format="text")
    # Extract keywords
    try:
        keywords = kw_model.extract_keywords(
            tokenized_text,
            keyphrase_ngram_range=(1,4),
            stop_words=stop_words_vi,
            top_n=10,
            use_mmr=True,
            nr_candidates=50,
            diversity=0.7
        )
        user_keywords = [kw[0] for kw in keywords]
        print(f"ğŸ”‘ Extracted keywords: {user_keywords}")
        
        if not user_keywords:
            print("âš ï¸ No keywords extracted. Using original input.")
            user_keywords = [user_input]
    except Exception as e:
        print(f"âš ï¸ Keyword extraction failed: {e}. Using original input.")
        user_keywords = [user_input]
    
    # Extract atmosphere tags and add to search
    atmosphere_tags = extract_atmosphere_tags(user_input)
    if atmosphere_tags:
        print(f"ğŸ·ï¸ Detected preferences: {', '.join(atmosphere_tags)}")
        user_keywords.extend(atmosphere_tags)
    
    # Encode user query
    search_query = " ".join(user_keywords)
    user_vec = embed_model.encode(search_query)
    
    # Calculate similarities efficiently
    similarities = cosine_similarity([user_vec], list(df["embedding"]))[0]
    
    # Start with full dataframe
    filtered_df = df.copy()
    
    # Filter by city if specified
    if city_filter:
        filtered_df = filtered_df[filtered_df["city"].str.contains(city_filter, case=False, na=False)]
        print(f"ğŸ“ Filtering by city: {city_filter}")
    
    # Filter by cuisine if specified
    if cuisine_filter:
        filtered_df = filtered_df[filtered_df["cuisine"].str.contains(cuisine_filter, case=False, na=False)]
        print(f"ğŸ½ï¸ Filtering by cuisine: {cuisine_filter}")
    
    # Filter by price range if specified
    if price_filter:
        filtered_df = filtered_df[filtered_df["price_range"] == price_filter]
        print(f"ğŸ’° Filtering by price: {price_filter}")
    
    # Check if we have results
    if filtered_df.empty:
        print(f"âš ï¸ No restaurants found with the specified filters.")
        print("ğŸ’¡ Try broadening your search criteria.")
        return pd.DataFrame()
    
    # Get similarities for filtered restaurants
    filtered_indices = filtered_df.index
    filtered_similarities = similarities[filtered_indices]
    
    # Calculate weighted scores
    if use_rating:
        filtered_df = filtered_df.copy()
        filtered_df["similarity"] = filtered_similarities
        filtered_df["final_score"] = filtered_df.apply(
            lambda row: calculate_weighted_score(row, row["similarity"]), axis=1
        )
        sort_column = "final_score"
    else:
        filtered_df = filtered_df.copy()
        filtered_df["similarity"] = filtered_similarities
        filtered_df["final_score"] = filtered_similarities
        sort_column = "final_score"
    
    # Get top recommendations
    recommendations = filtered_df.sort_values(by=sort_column, ascending=False).head(top_n)
    
    # Display results
    print(f"\nğŸ† Top {len(recommendations)} recommended restaurants:")
    print("=" * 80)
    for idx, (_, row) in enumerate(recommendations.iterrows(), 1):
        # Truncate tags for display
        tags_display = row['tags'][:80] + "..." if len(row['tags']) > 80 else row['tags']
        print(f"\n{idx}. ğŸ½ï¸ {row['name']}")
        print(f"   ğŸ“ {row['city']} | ğŸ´ {row['cuisine']} | ğŸ’µ {row['price_range']}")
        print(f"   â­ {row['rating']:.1f} | ğŸ¯ Match: {row['similarity']:.3f}")
        print(f"   ğŸ·ï¸ {tags_display}")
    
    print("=" * 80)
    
    return recommendations[["name", "city", "cuisine", "price_range", "tags", "rating", "similarity", "final_score"]]

def interactive_search():
    """Interactive restaurant search with smart filters"""
    print("\n" + "="*80)
    print("ğŸœ VIETNAMESE RESTAURANT RECOMMENDATION SYSTEM")
    print("="*80)
    
    user_input = input("\nğŸ—£ï¸ Báº¡n muá»‘n Äƒn gÃ¬ hÃ´m nay? (What do you want to eat today?): ").strip()
    
    if not user_input:
        print("âš ï¸ Please enter something!")
        return
    
    # Auto-extract filters from user input
    city = extract_city(user_input)
    cuisine = extract_cuisine(user_input)
    price = extract_price_preference(user_input)
    
    # Display detected filters
    print("\nğŸ” Analyzing your request...")
    if city:
        print(f"âœ… Detected city: {city}")
    if cuisine:
        print(f"âœ… Detected cuisine: {cuisine}")
    if price:
        print(f"âœ… Detected price range: {price}")
    
    # Get recommendations
    results = recommend_restaurants(
        user_input, 
        city_filter=city, 
        cuisine_filter=cuisine,
        price_filter=price,
        top_n=5
    )
    
    # Option to see more or refine search
    if not results.empty:
        print("\nğŸ’¬ Options:")
        print("  1. See more recommendations (type 'more')")
        print("  2. Filter by city (type city name)")
        print("  3. New search (type 'new')")
        print("  4. Exit (type 'exit')")
        
        choice = input("\nYour choice: ").strip().lower()
        
        if choice == 'more':
            recommend_restaurants(
                user_input, 
                city_filter=city, 
                cuisine_filter=cuisine,
                price_filter=price,
                top_n=10
            )
        elif choice == 'new':
            interactive_search()
        elif choice in ['Ä‘Ã  náºµng', 'hÃ  ná»™i', 'há»“ chÃ­ minh', 'nha trang', 'Ä‘Ã  láº¡t']:
            recommend_restaurants(
                user_input, 
                city_filter=choice.title(),
                cuisine_filter=cuisine,
                price_filter=price,
                top_n=5
            )
        elif choice != 'exit':
            print("Invalid option. Exiting...")

if __name__ == "__main__":
    interactive_search()