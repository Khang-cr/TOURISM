import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from underthesea import word_tokenize
import numpy as np
import torch
import re
from collections import Counter

# Try to import KeyBERT, fall back to simple extraction if it fails
try:
    from keybert import KeyBERT
    KEYBERT_AVAILABLE = True
    print("âœ… KeyBERT loaded successfully")
except ImportError as e:
    KEYBERT_AVAILABLE = False
    print(f"âš ï¸ KeyBERT not available. Using fallback keyword extraction")

# Load data
print("ğŸ“‚ Loading data...")
restaurants_df = pd.read_csv(r"C:\python\Projects\TOURISM\AI\Data-master\restaurants_100_improved.csv")
menus_df = pd.read_csv(r"C:\python\Projects\TOURISM\AI\Data-master\menus_100_improved.csv")

# Merge restaurant and menu data
print("ğŸ”— Merging restaurant and menu data...")
# Create a mapping from restaurant_id to restaurant info
restaurant_info = restaurants_df.set_index('restaurant_id')[['name', 'city', 'cuisine', 'price_range', 'rating', 'tags']].to_dict('index')

# Add restaurant info to menu items
menus_df['restaurant_name'] = menus_df['restaurant_id'].map(lambda x: restaurant_info.get(x, {}).get('name', 'Unknown'))
menus_df['city'] = menus_df['restaurant_id'].map(lambda x: restaurant_info.get(x, {}).get('city', 'Unknown'))
menus_df['cuisine'] = menus_df['restaurant_id'].map(lambda x: restaurant_info.get(x, {}).get('cuisine', 'Unknown'))
menus_df['restaurant_rating'] = menus_df['restaurant_id'].map(lambda x: restaurant_info.get(x, {}).get('rating', 0))
menus_df['restaurant_tags'] = menus_df['restaurant_id'].map(lambda x: restaurant_info.get(x, {}).get('tags', ''))
menus_df['price_range'] = menus_df['restaurant_id'].map(lambda x: restaurant_info.get(x, {}).get('price_range', 'â‚«â‚«'))

# Clean data
for col in ['dish_name', 'category', 'description', 'tags', 'city', 'cuisine', 'restaurant_name', 'restaurant_tags']:
    if col in menus_df.columns:
        menus_df[col] = menus_df[col].fillna("").astype(str)

menus_df['price_vnd'] = pd.to_numeric(menus_df['price_vnd'], errors='coerce').fillna(0)
menus_df['restaurant_rating'] = pd.to_numeric(menus_df['restaurant_rating'], errors='coerce').fillna(0)

# Initialize models
print("ğŸ¤– Loading AI models...")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"   Using device: {device}")

embed_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)

# Initialize KeyBERT if available
if KEYBERT_AVAILABLE:
    try:
        kw_model = KeyBERT(model=embed_model)
        print("âœ… KeyBERT initialized")
    except Exception as e:
        print(f"âš ï¸ KeyBERT initialization failed: {e}")
        KEYBERT_AVAILABLE = False

# Vietnamese stop words
stop_words_vi = [
    'cá»§a', 'vÃ ', 'cÃ¡c', 'cÃ³', 'Ä‘Æ°á»£c', 'cho', 'lÃ ', 'vá»›i', 
    'Ä‘á»ƒ', 'trong', 'khÃ´ng', 'má»™t', 'nÃ y', 'nhá»¯ng', 'Ä‘Ã£', 
    'nhÆ°', 'bá»Ÿi', 'tá»«', 'hoáº·c', 'Ä‘áº¿n', 'khi', 'cÅ©ng', 'nhÆ°ng',
    'thÃ¬', 'nÃ o', 'Ä‘Ã¢y', 'ráº¥t', 'sáº½', 'vÃ o', 'ra', 'á»Ÿ', 'vá»'
]

# Food keywords for better matching
food_keywords = {
    'phá»Ÿ': ['phá»Ÿ', 'pho'],
    'bÃºn': ['bÃºn', 'bun'],
    'cÆ¡m': ['cÆ¡m', 'com', 'rice', 'cÆ¡m táº¥m'],
    'bÃ¡nh mÃ¬': ['bÃ¡nh mÃ¬', 'banh mi'],
    'nem': ['nem', 'cháº£ giÃ²', 'spring roll'],
    'gá»i': ['gá»i', 'salad', 'goi cuon'],
    'sushi': ['sushi', 'sashimi'],
    'ramen': ['ramen', 'mÃ¬ nháº­t'],
    'bbq': ['bbq', 'nÆ°á»›ng', 'grilled', 'bulgogi'],
    'curry': ['curry', 'cÃ  ri'],
    'pasta': ['pasta', 'má»³ Ã½', 'spaghetti'],
    'pizza': ['pizza'],
    'burger': ['burger', 'hamburger'],
    'steak': ['steak', 'bÃ­t táº¿t'],
    'chay': ['chay', 'vegetarian', 'vegan'],
    'háº£i sáº£n': ['háº£i sáº£n', 'seafood', 'tÃ´m', 'cua', 'cÃ¡'],
    'gÃ ': ['gÃ ', 'chicken'],
    'bÃ²': ['bÃ²', 'beef'],
    'heo': ['heo', 'pork', 'lá»£n'],
    'trÃ¡ng miá»‡ng': ['trÃ¡ng miá»‡ng', 'dessert', 'ngá»t', 'chÃ¨', 'kem'],
    'Ä‘á»“ uá»‘ng': ['Ä‘á»“ uá»‘ng', 'drink', 'nÆ°á»›c', 'trÃ ', 'cÃ  phÃª']
}

def simple_keyword_extraction(text, stop_words, top_n=10):
    """Fallback keyword extraction without KeyBERT"""
    text = text.lower()
    try:
        tokens = word_tokenize(text, format="text").split()
    except:
        tokens = text.split()
    
    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]
    word_freq = Counter(tokens)
    keywords = [word for word, _ in word_freq.most_common(top_n)]
    return keywords

def extract_city(user_input):
    """Extract city from user input"""
    user_lower = user_input.lower()
    city_keywords = {
        "ÄÃ  Náºµng": ["Ä‘Ã  náºµng", "da nang", "Ä‘n", "danang"],
        "Há»“ ChÃ­ Minh": ["há»“ chÃ­ minh", "hcm", "sÃ i gÃ²n", "saigon", "tphcm", "tp hcm"],
        "HÃ  Ná»™i": ["hÃ  ná»™i", "ha noi", "hn", "hanoi"],
        "Nha Trang": ["nha trang"],
        "ÄÃ  Láº¡t": ["Ä‘Ã  láº¡t", "da lat", "dalat"],
        "Cáº§n ThÆ¡": ["cáº§n thÆ¡", "can tho"],
        "Huáº¿": ["huáº¿", "hue"],
        "Háº£i PhÃ²ng": ["háº£i phÃ²ng", "hai phong"],
        "VÅ©ng TÃ u": ["vÅ©ng tÃ u", "vung tau"],
        "PhÃº Quá»‘c": ["phÃº quá»‘c", "phu quoc"]
    }
    
    for city, keywords in city_keywords.items():
        if any(kw in user_lower for kw in keywords):
            return city
    return None

def extract_price_preference(user_input):
    """Extract price preference from user input"""
    user_lower = user_input.lower()
    
    cheap_keywords = ['ráº»', 'bÃ¬nh dÃ¢n', 'sinh viÃªn', 'tiáº¿t kiá»‡m', 'budget', 'cheap', 'dÆ°á»›i 100k', 'dÆ°á»›i 100']
    mid_keywords = ['vá»«a pháº£i', 'trung bÃ¬nh', 'há»£p lÃ½', '100k-200k']
    expensive_keywords = ['cao cáº¥p', 'sang trá»ng', 'Ä‘áº¯t', 'fine dining', 'luxury', 'trÃªn 200k']
    
    if any(kw in user_lower for kw in cheap_keywords):
        return 'cheap'  # < 100k
    elif any(kw in user_lower for kw in expensive_keywords):
        return 'expensive'  # > 200k
    elif any(kw in user_lower for kw in mid_keywords):
        return 'mid'  # 100k-200k
    return None

def extract_category(user_input):
    """Extract food category from user input"""
    user_lower = user_input.lower()
    
    if any(kw in user_lower for kw in ['khai vá»‹', 'appetizer', 'starter', 'gá»i', 'nem']):
        return 'Khai vá»‹'
    elif any(kw in user_lower for kw in ['mÃ³n chÃ­nh', 'main', 'main course', 'bá»¯a chÃ­nh']):
        return 'MÃ³n chÃ­nh'
    elif any(kw in user_lower for kw in ['trÃ¡ng miá»‡ng', 'dessert', 'ngá»t', 'chÃ¨', 'bÃ¡nh ngá»t']):
        return 'TrÃ¡ng miá»‡ng'
    elif any(kw in user_lower for kw in ['Ä‘á»“ uá»‘ng', 'drink', 'nÆ°á»›c', 'uá»‘ng', 'trÃ ', 'cÃ  phÃª']):
        return 'Äá»“ uá»‘ng'
    return None

# Pre-compute food embeddings
print("ğŸ“Š Pre-computing food embeddings...")
menus_df["search_text"] = (
    menus_df["dish_name"] + " " + 
    menus_df["description"] + " " + 
    menus_df["tags"] + " " + 
    menus_df["category"] + " " +
    menus_df["cuisine"] + " " +
    menus_df["restaurant_tags"]
)
food_embeddings = embed_model.encode(menus_df["search_text"].tolist(), show_progress_bar=True)
menus_df["embedding"] = list(food_embeddings)

print(f"âœ… Loaded {len(menus_df)} dishes from {restaurants_df['name'].nunique()} restaurants")

def recommend_food(user_input, city_filter=None, price_filter=None, category_filter=None, top_n=10):
    """Recommend food dishes based on user input"""
    
    if not user_input.strip():
        print("âš ï¸ Please tell me what you want to eat!")
        return pd.DataFrame()
    
    # Extract keywords
    try:
        if KEYBERT_AVAILABLE:
            tokenized_text = word_tokenize(user_input, format="text")
            keywords = kw_model.extract_keywords(
                tokenized_text,
                keyphrase_ngram_range=(1, 3),
                stop_words=stop_words_vi,
                top_n=10,
                use_mmr=True,
                diversity=0.7
            )
            user_keywords = [kw[0] for kw in keywords]
            print(f"ğŸ”‘ Keywords (KeyBERT): {user_keywords}")
        else:
            user_keywords = simple_keyword_extraction(user_input, stop_words_vi, top_n=10)
            print(f"ğŸ”‘ Keywords (Simple): {user_keywords}")
        
        if not user_keywords:
            user_keywords = [user_input]
    except Exception as e:
        print(f"âš ï¸ Keyword extraction failed: {e}")
        user_keywords = [user_input]
    
    # Encode user query
    search_query = " ".join(user_keywords)
    user_vec = embed_model.encode(search_query)
    
    # Calculate similarities
    similarities = cosine_similarity([user_vec], list(menus_df["embedding"]))[0]
    
    # Start with full dataframe
    filtered_df = menus_df.copy()
    
    # Filter by city
    if city_filter:
        filtered_df = filtered_df[filtered_df["city"].str.contains(city_filter, case=False, na=False)]
        print(f"ğŸ“ Filtering by city: {city_filter}")
    
    # Filter by price
    if price_filter:
        if price_filter == 'cheap':
            filtered_df = filtered_df[filtered_df["price_vnd"] < 100000]
            print(f"ğŸ’° Filtering by price: < 100,000 VNÄ")
        elif price_filter == 'mid':
            filtered_df = filtered_df[(filtered_df["price_vnd"] >= 100000) & (filtered_df["price_vnd"] <= 200000)]
            print(f"ğŸ’° Filtering by price: 100,000 - 200,000 VNÄ")
        elif price_filter == 'expensive':
            filtered_df = filtered_df[filtered_df["price_vnd"] > 200000]
            print(f"ğŸ’° Filtering by price: > 200,000 VNÄ")
    
    # Filter by category
    if category_filter:
        filtered_df = filtered_df[filtered_df["category"].str.contains(category_filter, case=False, na=False)]
        print(f"ğŸ½ï¸ Filtering by category: {category_filter}")
    
    # Check if we have results
    if filtered_df.empty:
        print(f"âš ï¸ No dishes found with the specified filters.")
        print("ğŸ’¡ Try broadening your search criteria.")
        return pd.DataFrame()
    
    # Get similarities for filtered items
    filtered_indices = filtered_df.index
    filtered_similarities = similarities[filtered_indices]
    
    # Add similarity scores
    filtered_df = filtered_df.copy()
    filtered_df["similarity"] = filtered_similarities
    
    # Calculate final score (70% similarity + 30% restaurant rating)
    filtered_df["final_score"] = (
        0.7 * filtered_df["similarity"] + 
        0.3 * (filtered_df["restaurant_rating"] / 5.0)
    )
    
    # Get top recommendations
    recommendations = filtered_df.sort_values(by="final_score", ascending=False).head(top_n)
    
    # Display results
    print(f"\nğŸ† Top {len(recommendations)} recommended dishes:")
    print("=" * 90)
    
    for idx, (_, row) in enumerate(recommendations.iterrows(), 1):
        print(f"\n{idx}. ğŸ½ï¸ {row['dish_name']} - {int(row['price_vnd']):,} VNÄ")
        print(f"   ğŸª {row['restaurant_name']} ({row['city']})")
        print(f"   ğŸ´ {row['cuisine']} | ğŸ“‚ {row['category']}")
        print(f"   â­ Restaurant: {row['restaurant_rating']:.1f} | ğŸ¯ Match: {row['similarity']:.3f}")
        print(f"   ğŸ“ {row['description']}")
        print(f"   ğŸ·ï¸ {row['tags']}")
    
    print("=" * 90)
    
    return recommendations[[
        "dish_name", "restaurant_name", "city", "cuisine", "category",
        "price_vnd", "description", "restaurant_rating", "similarity", "final_score"
    ]]

def interactive_food_search():
    """Interactive food search system"""
    print("\n" + "="*90)
    print("ğŸœ VIETNAMESE FOOD RECOMMENDATION SYSTEM")
    print("="*90)
    print("\nTips: You can search by:")
    print("  â€¢ Dish name (e.g., 'phá»Ÿ', 'sushi', 'pizza')")
    print("  â€¢ Taste/Style (e.g., 'cay', 'ngá»t', 'chua', 'spicy')")
    print("  â€¢ City (e.g., 'HÃ  Ná»™i', 'SÃ i GÃ²n', 'ÄÃ  Náºµng')")
    print("  â€¢ Price (e.g., 'ráº»', 'budget', 'cao cáº¥p')")
    print("  â€¢ Category (e.g., 'mÃ³n chÃ­nh', 'trÃ¡ng miá»‡ng', 'Ä‘á»“ uá»‘ng')")
    
    user_input = input("\nğŸ—£ï¸ Báº¡n muá»‘n Äƒn gÃ¬ hÃ´m nay? (What do you want to eat?): ").strip()
    
    if not user_input:
        print("âš ï¸ Please enter something!")
        return
    
    # Auto-extract filters
    city = extract_city(user_input)
    price = extract_price_preference(user_input)
    category = extract_category(user_input)
    
    # Display detected filters
    print("\nğŸ” Analyzing your request...")
    if city:
        print(f"âœ… Detected city: {city}")
    if price:
        print(f"âœ… Detected price preference: {price}")
    if category:
        print(f"âœ… Detected category: {category}")
    
    # Get recommendations
    results = recommend_food(
        user_input,
        city_filter=city,
        price_filter=price,
        category_filter=category,
        top_n=10
    )
    
    # Options
    if not results.empty:
        print("\nğŸ’¬ Options:")
        print("  1. New search (type 'new')")
        print("  2. Filter by city (type city name)")
        print("  3. Show cheaper options (type 'cheap')")
        print("  4. Show more expensive options (type 'expensive')")
        print("  5. Exit (type 'exit')")
        
        choice = input("\nYour choice: ").strip().lower()
        
        if choice == 'new':
            interactive_food_search()
        elif choice == 'cheap':
            recommend_food(user_input, city_filter=city, price_filter='cheap', category_filter=category, top_n=10)
        elif choice == 'expensive':
            recommend_food(user_input, city_filter=city, price_filter='expensive', category_filter=category, top_n=10)
        elif choice in ['Ä‘Ã  náºµng', 'hÃ  ná»™i', 'há»“ chÃ­ minh', 'sÃ i gÃ²n', 'nha trang']:
            city_map = {
                'sÃ i gÃ²n': 'Há»“ ChÃ­ Minh',
                'há»“ chÃ­ minh': 'Há»“ ChÃ­ Minh',
                'hÃ  ná»™i': 'HÃ  Ná»™i',
                'Ä‘Ã  náºµng': 'ÄÃ  Náºµng',
                'nha trang': 'Nha Trang'
            }
            recommend_food(user_input, city_filter=city_map.get(choice, choice.title()), price_filter=price, category_filter=category, top_n=10)
        elif choice == 'exit':
            print("Thanks for using the system! ğŸ‘‹")

if __name__ == "__main__":
    interactive_food_search()